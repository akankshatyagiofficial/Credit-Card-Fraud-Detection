{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>id_01</th>\n",
       "      <th>id_02</th>\n",
       "      <th>id_03</th>\n",
       "      <th>id_04</th>\n",
       "      <th>id_05</th>\n",
       "      <th>id_06</th>\n",
       "      <th>id_07</th>\n",
       "      <th>id_08</th>\n",
       "      <th>id_09</th>\n",
       "      <th>...</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70787.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>samsung browser 6.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2220x1080</td>\n",
       "      <td>match_status:2</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>mobile</td>\n",
       "      <td>SAMSUNG SM-G892A Build/NRD90M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987008</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>98945.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>mobile safari 11.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1334x750</td>\n",
       "      <td>match_status:1</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>mobile</td>\n",
       "      <td>iOS Device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987010</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>191631.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>chrome 62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987011</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>221832.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>chrome 62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>desktop</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7460.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>chrome 62.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1280x800</td>\n",
       "      <td>match_status:2</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>desktop</td>\n",
       "      <td>MacOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  id_01     id_02  id_03  id_04  id_05  id_06  id_07  id_08  \\\n",
       "0        2987004    0.0   70787.0    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1        2987008   -5.0   98945.0    NaN    NaN    0.0   -5.0    NaN    NaN   \n",
       "2        2987010   -5.0  191631.0    0.0    0.0    0.0    0.0    NaN    NaN   \n",
       "3        2987011   -5.0  221832.0    NaN    NaN    0.0   -6.0    NaN    NaN   \n",
       "4        2987016    0.0    7460.0    0.0    0.0    1.0    0.0    NaN    NaN   \n",
       "\n",
       "   id_09  ...                id_31  id_32      id_33           id_34  id_35  \\\n",
       "0    NaN  ...  samsung browser 6.2   32.0  2220x1080  match_status:2      T   \n",
       "1    NaN  ...   mobile safari 11.0   32.0   1334x750  match_status:1      T   \n",
       "2    0.0  ...          chrome 62.0    NaN        NaN             NaN      F   \n",
       "3    NaN  ...          chrome 62.0    NaN        NaN             NaN      F   \n",
       "4    0.0  ...          chrome 62.0   24.0   1280x800  match_status:2      T   \n",
       "\n",
       "  id_36 id_37  id_38  DeviceType                     DeviceInfo  \n",
       "0     F     T      T      mobile  SAMSUNG SM-G892A Build/NRD90M  \n",
       "1     F     F      T      mobile                     iOS Device  \n",
       "2     F     T      T     desktop                        Windows  \n",
       "3     F     T      T     desktop                            NaN  \n",
       "4     F     T      T     desktop                          MacOS  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_identity_df = pd.read_csv('./ieee-fraud-detection/train_identity.csv')\n",
    "\n",
    "train_identity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction_df = pd.read_csv('./ieee-fraud-detection/train_transaction.csv')\n",
    "\n",
    "train_transaction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{train_identity_df.shape = }')\n",
    "print(f'{train_transaction_df.shape = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(train_identity_df['TransactionID']) - set(train_transaction_df['TransactionID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(train_transaction_df['TransactionID']) - set(train_identity_df['TransactionID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_identity_df = pd.read_csv('./ieee-fraud-detection/test_identity.csv')\n",
    "\n",
    "test_identity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transaction_df = pd.read_csv('./ieee-fraud-detection/test_transaction.csv')\n",
    "\n",
    "test_transaction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{test_identity_df.shape = }')\n",
    "print(f'{test_transaction_df.shape = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the identity and transaction tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_transaction_df.merge(train_identity_df, on='TransactionID', how='left')\n",
    "test_df = test_transaction_df.merge(test_identity_df, on='TransactionID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{train_df.shape =}')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{test_df.shape = }')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns that have too many missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentages = train_df.isnull().mean()\n",
    "missing_thr = 0.9\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "missing_percentages[missing_percentages > missing_thr].sort_values(ascending=True).plot(kind='barh')\n",
    "plt.xlabel('Percentage of Missing Values')\n",
    "plt.ylabel('Columns')\n",
    "plt.title(f'Percentage of Missing Values by in columns with > {missing_thr * 100} % missing values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(train_df)\n",
    "n_cols_before = train_df.shape[1]\n",
    "train_df = train_df.loc[:, train_df.isnull().mean() < missing_thr]\n",
    "print(f\"Number of columns {n_cols_before} -> {train_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create os feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['id_30'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature called id_30\n",
    "train_df['os'] = train_df['id_30'].str.split(' ', n=1, expand=True)[0]\n",
    "train_df.drop('id_30', axis=1, inplace=True)\n",
    "train_df['os'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Screen size feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['id_33'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['width', 'height']] = train_df['id_33'].str.split('x', n=1, expand=True).apply(pd.to_numeric)\n",
    "train_df.drop('id_33', axis=1, inplace=True)\n",
    "train_df[['width', 'height']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Browser feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['id_31'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['browser'] = train_df['id_31'].str.split(' ', expand=True)[0].str.lower()\n",
    "train_df.drop('id_31', axis=1, inplace=True)\n",
    "train_df['browser'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['browser'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map browser names to most common ones and group others into \"other\".\n",
    "browser_mapping = {\n",
    "    'samsung': 'samsung',\n",
    "    'samsung/sm-g532m': 'samsung',\n",
    "    'samsung/sch': 'samsung',\n",
    "    'samsung/sm-g531h': 'samsung',\n",
    "    'mobile': 'mobile',\n",
    "    'chrome': 'chrome',\n",
    "    'chromium': 'chrome',\n",
    "    'firefox': 'firefox',\n",
    "    'mozilla/firefox': 'firefox',\n",
    "    'waterfox': 'firefox',\n",
    "    'cyberfox': 'firefox',\n",
    "    'icedragon': 'firefox',\n",
    "    'edge': 'edge',\n",
    "    'ie': 'ie',\n",
    "    'safari': 'safari',\n",
    "    'android': 'android',\n",
    "    'generic/android': 'android',\n",
    "    'opera': 'opera',\n",
    "    'silk': 'opera',\n",
    "    'palemoon': 'other',\n",
    "    'maxthon': 'other',\n",
    "    'line': 'other',\n",
    "    'iron': 'other',\n",
    "    'blu/dash': 'other',\n",
    "    'seamonkey': 'other',\n",
    "    'm4tel/m4': 'other',\n",
    "    'comodo': 'other',\n",
    "    'lanix/ilium': 'other',\n",
    "    'inco/minion': 'other',\n",
    "    'cherry': 'other',\n",
    "    'google': 'google',\n",
    "    'facebook': 'facebook',\n",
    "    'aol': 'other',\n",
    "    'zte/blade': 'other',\n",
    "    'nokia/lumia': 'other',\n",
    "    'lg/k-200': 'other',\n",
    "    'microsoft/windows': 'windows',\n",
    "    np.nan: 'unknown'\n",
    "}\n",
    "\n",
    "train_df['browser'] = train_df['browser'].map(browser_mapping)\n",
    "\n",
    "train_df['browser'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transaction Hour and day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['TransactionHour'] = (train_df['TransactionDT'] // (60 * 60)) % 24\n",
    "train_df['TransactionDayOfWeek'] = (train_df['TransactionDT'] // (60 * 60 * 24)) % 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_cols = [c for c in train_df.columns if c.startswith(\"V\")]\n",
    "\n",
    "v_df = train_df[v_cols]\n",
    "missing_counts = v_df.isnull().sum()\n",
    "groups = {}\n",
    "for col, count in missing_counts.items():\n",
    "    groups.setdefault(count, []).append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "count = 0\n",
    "new_v_features = []\n",
    "for group in groups.values():\n",
    "    df_group = train_df[group].copy()\n",
    "    df_group.fillna(-999, inplace=True)\n",
    "    v_normalized = StandardScaler().fit_transform(df_group)\n",
    "    pca = PCA().fit(v_normalized)\n",
    "    explained_variance = pca.explained_variance_ratio_.cumsum()\n",
    "    n_components = (explained_variance >= 0.9).argmax() + 1  # Find the first index where variance >= 90%\n",
    "    print(f\"Group: {group}, Components to Retain: {n_components}\")\n",
    "    \n",
    "    pca_reduced = PCA(n_components=n_components)\n",
    "    reduced_data = pca_reduced.fit_transform(v_normalized)\n",
    "    for i in range(n_components):\n",
    "        train_df[f'V_pca_{count}'] = reduced_data[:, i]\n",
    "        new_v_features.append(f'V_pca_{count}')\n",
    "        count += 1\n",
    "\n",
    "print(f'Total V features created: {len(new_v_features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_email_features(train_df, col):\n",
    "    train_df[col] = train_df[col].fillna('unknown')\n",
    "    fraud_correlation = train_df.groupby(col)['isFraud'].mean()\n",
    "    train_df[f'{col}_fraud_corr'] = train_df[col].map(fraud_correlation)\n",
    "    \n",
    "    common_providers = ['gmail.com', 'yahoo.com', 'hotmail.com', 'outlook.com', 'icloud.com']\n",
    "    train_df[f'{col}_email_provider'] = train_df[col].apply(\n",
    "        lambda x: x if x in common_providers else 'other'\n",
    "    )\n",
    "    train_df[f'{col}_email_tld'] = train_df[col].str.split(' ', n=1, expand=True).apply(\n",
    "        lambda x: x[1] if len(x) > 1 else 'unknown'\n",
    "    )\n",
    "\n",
    "create_email_features(train_df, 'P_emaildomain')\n",
    "create_email_features(train_df, 'R_emaildomain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_categorical_features = ([\n",
    "    'ProductCD',\n",
    "    'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n",
    "    'addr1', 'addr2',\n",
    "    'P_emaildomain_email_provider', 'P_emaildomain_email_tld',\n",
    "    'R_emaildomain_email_provider', 'R_emaildomain_email_tld',\n",
    "    'DeviceType', 'DeviceInfo',\n",
    "    'os', 'browser',\n",
    "]\n",
    "+ [f'id_{i}' for i in range(12, 39)] # id features\n",
    "+ [f'M{i}' for i in range(1, 10)]  # M features\n",
    ")\n",
    "\n",
    "cat_thr = 15\n",
    "categorical_features = [c for c in cand_categorical_features if c in train_df and train_df[c].nunique() < cat_thr]\n",
    "\n",
    "numerical_features = (\n",
    "    ['TransactionAmt', 'TransactionHour', 'TransactionDayOfWeek', 'dist1']\n",
    "    + ['P_emaildomain_fraud_corr', 'R_emaildomain_fraud_corr']\n",
    "    + new_v_features  # V features\n",
    "    + [f'D{i}' for i in range(1, 15) if f'D{i}' in train_df.columns] # D features.\n",
    "    + [c for c in train_df.columns if c.startswith(\"C\")] # C features\n",
    "    + [c for c in cand_categorical_features if c in train_df.columns and train_df[c].nunique() >= cat_thr and c != \"DeviceInfo\"]\n",
    "    + ['width', 'height']\n",
    ")\n",
    "\n",
    "print(categorical_features)\n",
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers\n",
    "\n",
    "Convert outliers to NaNs so that they can be imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# cand_outlier_cols = [c for c in numerical_features if \"pca\" not in c and \"fraud_corr\" not in c]\n",
    "# num_features = len(cand_outlier_cols)\n",
    "# cols = 4\n",
    "# rows = math.ceil(num_features / cols)\n",
    "\n",
    "# fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows), sharex=False)\n",
    "# axes = axes.flatten()\n",
    "# for i, col in enumerate(cand_outlier_cols):\n",
    "   \n",
    "#     sns.boxplot(ax=axes[i], x='isFraud', y=col, data=train_df, hue='isFraud')\n",
    "#     axes[i].set_title(f'{col} Box Plot by isFraud')\n",
    "#     axes[i].set_ylabel(col)\n",
    "#     axes[i].set_xlabel('isFraud')\n",
    "#     axes[i].legend(title='isFraud')\n",
    "# for j in range(i + 1, len(axes)):\n",
    "#     axes[j].axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.suptitle('Before outlier removal')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use IQR method for outlier removal\n",
    "\n",
    "# If outliers are removed for features, the validation auc of RandomForest reduces from 0.9337 to 0.9317.\n",
    "# So the outlier removal is disabled.\n",
    "\n",
    "\n",
    "# for col in cand_categorical_features:\n",
    "#     Q1 = train_df[col].quantile(0.25)\n",
    "#     Q3 = train_df[col].quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     lower_bound = Q1 - 1.5 * IQR\n",
    "#     upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "#     # Mark values outside the bounds as NaN\n",
    "#     train_df.loc[(train_df[col] < lower_bound) |  (train_df[col] > upper_bound), col] = np.nan\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows), sharex=False)\n",
    "# axes = axes.flatten()\n",
    "# for i, col in enumerate(cand_outlier_cols):\n",
    "   \n",
    "#     sns.boxplot(ax=axes[i], x='isFraud', y=col, data=train_df, hue='isFraud')\n",
    "#     axes[i].set_title(f'{col} Box Plot by isFraud')\n",
    "#     axes[i].set_ylabel(col)\n",
    "#     axes[i].set_xlabel('isFraud')\n",
    "#     axes[i].legend(title='isFraud')\n",
    "# for j in range(i + 1, len(axes)):\n",
    "#     axes[j].axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.suptitle('After outlier removal')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_df[numerical_features] = scaler.fit_transform(train_df[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_encoded = pd.get_dummies(train_df, columns=categorical_features, drop_first=True)\n",
    "new_categorical_columns = train_df_encoded.columns.difference(train_df.columns).tolist()\n",
    "new_categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df_encoded[new_categorical_columns + numerical_features]\n",
    "y = train_df_encoded['isFraud'].to_numpy()\n",
    "\n",
    "print(f'{X.shape = }')\n",
    "print(f'{y.shape = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(f'{X_train.shape = }')\n",
    "print(f'{y_train.shape = }')\n",
    "print(f'{X_val.shape = }')\n",
    "print(f'{y_val.shape = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in train_df_encoded[new_categorical_columns].columns]\n",
    "train_df_encoded[new_categorical_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn import metrics\n",
    "\n",
    "# rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [None, 10, 20, 30],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'max_features': ['sqrt', 'log2'],\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=rf, \n",
    "#     param_grid=param_grid, \n",
    "#     scoring='roc_auc',\n",
    "#     cv=5,\n",
    "#     verbose=2, \n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "# print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def evaluate(model, X_val, y_val):\n",
    "    preds_val = model.predict(X_val)\n",
    "    report_dict = metrics.classification_report(y_val, preds_val, output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "    formatted_report = report_df.round(4)\n",
    "    print(formatted_report)\n",
    "\n",
    "    probs_val = model.predict_proba(X_val)[:, 1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_val, probs_val)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print(f'val auc: {roc_auc:.4f}')\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.title('ROC curve')\n",
    "    plt.plot(fpr, tpr, label=f'AUC: {roc_auc:.2f}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(rf, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing value imputation\n",
    "\n",
    "Impute missing value for non-tree models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values for numerical columns with the mean\n",
    "for col in numerical_features:\n",
    "    mean_col = X_train[col].mean()\n",
    "    X_train[col] = X_train[col].fillna(mean_col)\n",
    "    X_val[col] = X_val[col].fillna(mean_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values for categorical columns with the mode\n",
    "for col in new_categorical_columns:\n",
    "    mode_col = X_train[col].mode()[0]\n",
    "    X_train[col] = X_train[col].fillna(mode_col)\n",
    "    X_val[col] = X_val[col].fillna(mode_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# svm = SVC()\n",
    "\n",
    "# svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(svm, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "evaluate(lr, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naives Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "evaluate(gnb, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
